{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubensolano2/GUIDES-AND-PRACTICES/blob/main/%20Disease_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giJo3pCUdFi9"
      },
      "source": [
        "#DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkTZvZd9eso_"
      },
      "outputs": [],
      "source": [
        "!mkdir -p '/content/drive/MyDrive/destination_folder/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ck9I9_5eceD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6887349-2292-43a6-9cd9-e82cc5edd158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar (child): /content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/images_001.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "!tar -xzf \"/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/images_001.tar.gz\" -C \"/content/drive/MyDrive/destination_folder/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKkOKzZ6gc2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "899eff22-1e8f-40e2-8e10-0498bd1dbc6d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-220d30477064>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    images = /content/drive/MyDrive/destination_folder/images\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "images = /content/drive/MyDrive/destination_folder/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz--fp-ijc_m"
      },
      "outputs": [],
      "source": [
        "single_label= pd.read_csv(\"/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/LongTailCXR/nih-cxr-lt_single-label_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK_N23LCj_Pe"
      },
      "outputs": [],
      "source": [
        "single_label[6:16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2aSKF7SPIvd"
      },
      "outputs": [],
      "source": [
        "miccai_train= pd.read_csv(\"/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZTgexh_QKqe"
      },
      "outputs": [],
      "source": [
        "miccai_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN1sK--0T4pX"
      },
      "source": [
        "1024 x 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFGflFTPdHu1"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvnEfrA6dEFQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDQBa8NNYPkk"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gW3XaNwg6wv"
      },
      "source": [
        "#windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP88UH-JzmZ9"
      },
      "source": [
        "##v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHcNfq6sgxNY"
      },
      "outputs": [],
      "source": [
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "def resize_image(image_np, target_shape=(512, 512)):\n",
        "    image_pil = Image.fromarray(image_np)\n",
        "    image_pil_resized = image_pil.resize(target_shape)\n",
        "    return np.array(image_pil_resized)\n",
        "\n",
        "def preprocess_ct_slices_from_directory(directory_path, image_ids, max_images=None, data_augmentation=False):\n",
        "    hu_windows = [(400, 2000), (-600, 1500), (50, 350), (30, 150), (50, 400)]\n",
        "    preprocessed_images = {}\n",
        "\n",
        "    filenames = sorted([f for f in os.listdir(directory_path) if f in image_ids])\n",
        "\n",
        "    for idx in range(1, len(filenames) - 1):\n",
        "        if max_images is not None and idx > max_images:\n",
        "            break\n",
        "\n",
        "        inferior_slice_path = os.path.join(directory_path, filenames[idx - 1])\n",
        "        key_slice_path = os.path.join(directory_path, filenames[idx])\n",
        "        superior_slice_path = os.path.join(directory_path, filenames[idx + 1])\n",
        "\n",
        "        if all(map(lambda x: x.lower().endswith('.png'), [inferior_slice_path, key_slice_path, superior_slice_path])):\n",
        "            inferior_slice = np.array(Image.open(inferior_slice_path))\n",
        "            key_slice = np.array(Image.open(key_slice_path))\n",
        "            superior_slice = np.array(Image.open(superior_slice_path))\n",
        "\n",
        "            # Redimensionar las imágenes a 512x512\n",
        "            inferior_slice = resize_image(inferior_slice)\n",
        "            key_slice = resize_image(key_slice)\n",
        "            superior_slice = resize_image(superior_slice)\n",
        "\n",
        "            windowed_slices = []\n",
        "            for level, width in hu_windows:\n",
        "                windowed_inferior = apply_hu_window(inferior_slice, level, width)\n",
        "                windowed_key = apply_hu_window(key_slice, level, width)\n",
        "                windowed_superior = apply_hu_window(superior_slice, level, width)\n",
        "\n",
        "                if windowed_inferior.shape == windowed_key.shape == windowed_superior.shape:\n",
        "                    three_channel_image = np.stack([windowed_inferior, windowed_key, windowed_superior], axis=2)\n",
        "                    windowed_slices.append(three_channel_image)\n",
        "                else:\n",
        "                    print(f\"Las imágenes {filenames[idx-1]}, {filenames[idx]}, y {filenames[idx+1]} tienen diferentes formas y no se pueden apilar.\")\n",
        "\n",
        "            preprocessed_images[filenames[idx]] = windowed_slices\n",
        "\n",
        "    return preprocessed_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYA-L8Ssznys"
      },
      "source": [
        "##v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbEo80D3uUa3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "def resize_image(image_np, target_shape=(512, 512)):\n",
        "    image_pil = Image.fromarray(image_np)\n",
        "    image_pil_resized = image_pil.resize(target_shape)\n",
        "    return np.array(image_pil_resized)\n",
        "\n",
        "def preprocess_ct_slices_from_directory(directory_path, image_ids, max_images=None, data_augmentation=False):\n",
        "    hu_windows = [(400, 2000), (-600, 1500), (50, 350), (30, 150), (50, 400)]\n",
        "    preprocessed_images = {}\n",
        "\n",
        "    filenames = sorted([f for f in os.listdir(directory_path) if f in image_ids])\n",
        "\n",
        "    # Agrupar imágenes por su identificador base\n",
        "    grouped_images = {}\n",
        "    for image_id in filenames:\n",
        "        base_id = re.match(r\"(\\d+)_\", image_id).group(1)\n",
        "        if base_id not in grouped_images:\n",
        "            grouped_images[base_id] = []\n",
        "        grouped_images[base_id].append(image_id)\n",
        "\n",
        "    for base_id, versions in grouped_images.items():\n",
        "        if len(versions) < 3:\n",
        "            continue  # Ignorar si no hay al menos 3 versiones\n",
        "\n",
        "        inferior_slice_path = os.path.join(directory_path, versions[0])\n",
        "        key_slice_path = os.path.join(directory_path, versions[1])\n",
        "        superior_slice_path = os.path.join(directory_path, versions[2])\n",
        "\n",
        "        inferior_slice = np.array(Image.open(inferior_slice_path))\n",
        "        key_slice = np.array(Image.open(key_slice_path))\n",
        "        superior_slice = np.array(Image.open(superior_slice_path))\n",
        "\n",
        "        # Redimensionar las imágenes a 512x512\n",
        "        inferior_slice = resize_image(inferior_slice)\n",
        "        key_slice = resize_image(key_slice)\n",
        "        superior_slice = resize_image(superior_slice)\n",
        "\n",
        "        windowed_slices = []\n",
        "        for level, width in hu_windows:\n",
        "            windowed_inferior = apply_hu_window(inferior_slice, level, width)\n",
        "            windowed_key = apply_hu_window(key_slice, level, width)\n",
        "            windowed_superior = apply_hu_window(superior_slice, level, width)\n",
        "\n",
        "            if windowed_inferior.shape == windowed_key.shape == windowed_superior.shape:\n",
        "                three_channel_image = np.stack([windowed_inferior, windowed_key, windowed_superior], axis=2)\n",
        "                windowed_slices.append(three_channel_image)\n",
        "            else:\n",
        "                print(f\"Las imágenes {versions[0]}, {versions[1]}, y {versions[2]} tienen diferentes formas y no se pueden apilar.\")\n",
        "\n",
        "        preprocessed_images[base_id] = windowed_slices\n",
        "\n",
        "    return preprocessed_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7aI7JHRzrTF"
      },
      "source": [
        "##v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVvFqwcW5ozF"
      },
      "source": [
        "Los datos pueden ser de una sola persona y haber una sola imagen que se le aplica las ventanas y esta se convierte en 5 diferentes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jkc1dhX3zsaV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "def resize_image(image_np, target_shape=(512, 512)):\n",
        "    image_pil = Image.fromarray(image_np)\n",
        "    image_pil_resized = image_pil.resize(target_shape)\n",
        "    return np.array(image_pil_resized)\n",
        "\n",
        "def preprocess_ct_slices_from_directory(directory_path, image_ids, max_images=None, data_augmentation=False):\n",
        "    start_time = time.time()\n",
        "    hu_windows = [(400, 2000), (-600, 1500), (50, 350), (30, 150), (50, 400)]\n",
        "    preprocessed_images = {}\n",
        "\n",
        "    print(\"Starting to read directory...\")\n",
        "    filenames = sorted([f for f in os.listdir(directory_path) if f in set(image_ids)])\n",
        "    print(f\"Time taken to read directory: {time.time() - start_time} seconds\")\n",
        "\n",
        "    for image_id in filenames:\n",
        "        windowed_slices = []\n",
        "\n",
        "        slice_start_time = time.time()\n",
        "        slice_path = os.path.join(directory_path, image_id)\n",
        "        slice_img = np.array(Image.open(slice_path))\n",
        "\n",
        "        # Resize the image to 512x512\n",
        "        resize_start_time = time.time()\n",
        "        slice_img = resize_image(slice_img)\n",
        "        print(f\"Time taken to resize image: {time.time() - resize_start_time} seconds\")\n",
        "\n",
        "        for level, width in hu_windows:\n",
        "            hu_start_time = time.time()\n",
        "            windowed_slice = apply_hu_window(slice_img, level, width)\n",
        "            print(f\"Time taken to apply HU window: {time.time() - hu_start_time} seconds\")\n",
        "\n",
        "            windowed_slices.append(windowed_slice)\n",
        "\n",
        "        print(f\"Time taken to process one slice: {time.time() - slice_start_time} seconds\")\n",
        "        preprocessed_images[image_id] = windowed_slices\n",
        "\n",
        "    print(f\"Total time taken: {time.time() - start_time} seconds\")\n",
        "    return preprocessed_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V4"
      ],
      "metadata": {
        "id": "rg8sIXbbcGw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si las imágenes son muy similares pero contienen detalles importantes que no se deben perder, una combinación ponderada podría ser más apropiada que simplemente tomar el promedio. Esto permite ajustar los pesos \\( w_1, w_2, w_3 \\) según la importancia relativa de cada imagen (clave, superior, inferior) en la captura de detalles significativos.\n",
        "\n",
        "### Combinación Ponderada\n",
        "La fórmula para la combinación ponderada sería:\n",
        "\n",
        "{Imagen Combinada} = w_1 \\times \\text{Imagen Clave} + w_2 \\times \\text{Imagen Superior} + w_3 \\times \\text{Imagen Inferior}\n",
        "\n",
        "\n",
        "Donde \\( w_1 + w_2 + w_3 = 1 \\).\n",
        "\n",
        "Los pesos pueden ser determinados empíricamente, o podrían basarse en algún criterio clínico o diagnóstico. Por ejemplo, si la imagen clave generalmente contiene la mayor cantidad de información diagnóstica, podría recibir un peso más alto.\n",
        "\n"
      ],
      "metadata": {
        "id": "w9-YzwTDGs8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo archivo CSV...\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv')\n",
        "\n",
        "# Variables para llevar registro del número de imágenes procesadas y máximo permitido\n",
        "image_count = 0\n",
        "max_images = 20\n",
        "\n",
        "# Función para aplicar la ventana HU\n",
        "def apply_hu_window(image, hu_min, hu_max):\n",
        "    image = np.clip(image, hu_min, hu_max)\n",
        "    return ((image - hu_min) / (hu_max - hu_min) * 255).astype(np.uint8)\n",
        "\n",
        "# Definir ventanas HU\n",
        "hu_windows = [(180, 230), (130, 180), (80, 130), (40, 80), (30, 50)]\n",
        "\n",
        "\n",
        "\n",
        "# Para almacenar imágenes procesadas\n",
        "imagen_procesada = []\n",
        "\n",
        "# Crear un diccionario que mapea subj_id a sus imágenes correspondientes\n",
        "print(\"Creando diccionario subj_id a imágenes...\")\n",
        "subj_id_to_images = {}\n",
        "for subj_id, group in df.groupby('subj_id'):\n",
        "    group['total_findings'] = group.drop(['No Finding', 'subj_id', 'id'], axis=1).sum(axis=1)\n",
        "    sorted_group = group.sort_values('total_findings', ascending=False)\n",
        "    subj_id_to_images[subj_id] = sorted_group\n",
        "\n",
        "# Procesar cada grupo de imágenes por paciente\n",
        "print(\"Procesando grupos de imágenes por paciente...\")\n",
        "for subj_id, images_df in subj_id_to_images.items():\n",
        "    if image_count >= max_images:\n",
        "        break\n",
        "\n",
        "    print(f\"Procesando subj_id: {subj_id}\")\n",
        "\n",
        "    # Determinar qué imágenes usar como corte clave, superior e inferior\n",
        "    if len(images_df) == 1:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = key_image\n",
        "        lower_image = key_image\n",
        "    elif len(images_df) == 2:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = upper_image\n",
        "    else:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = images_df.iloc[2]['id']\n",
        "\n",
        "    print(f\"Imágenes seleccionadas: Key: {key_image}, Upper: {upper_image}, Lower: {lower_image}\")\n",
        "\n",
        "    # Leer y combinar las imágenes seleccionadas\n",
        "    combined_image = np.zeros_like(cv2.imread(os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', key_image), cv2.IMREAD_GRAYSCALE), dtype=np.float64)\n",
        "\n",
        "    for weight, img_name in zip([0.7, 0.15, 0.15], [key_image, upper_image, lower_image]):\n",
        "        image_path = os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', img_name)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error al cargar la imagen: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        combined_image += weight * image\n",
        "\n",
        "    # Convertir combined_image a uint8 para futuras operaciones\n",
        "    combined_image = combined_image.astype(np.uint8)\n",
        "\n",
        "    # Aplicar las ventanas HU a la imagen combinada y guardar en la variable\n",
        "    for i, (hu_min, hu_max) in enumerate(hu_windows):\n",
        "        print(f\"Aplicando ventana HU {i+1} con rango ({hu_min}, {hu_max})...\")\n",
        "\n",
        "        # Imprimir los valores mínimos y máximos antes de aplicar la ventana HU\n",
        "        print(f\"Valores antes de aplicar ventana: Min = {np.min(combined_image)}, Max = {np.max(combined_image)}\")\n",
        "\n",
        "        iui = apply_hu_window(combined_image, hu_min, hu_max)\n",
        "\n",
        "        # Imprimir los valores mínimos y máximos después de aplicar la ventana HU\n",
        "        print(f\"Valores después de aplicar ventana: Min = {np.min(iui)}, Max = {np.max(iui)}\")\n",
        "\n",
        "        imagen_procesada.append(iui)\n",
        "\n",
        "    # Incrementar el contador de imágenes\n",
        "    image_count += 1\n"
      ],
      "metadata": {
        "id": "FkeV6u4EcIIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v5"
      ],
      "metadata": {
        "id": "qihfQiroTedM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Función para aplicar la ventana HU con nivel y ancho\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo archivo CSV...\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv')\n",
        "\n",
        "# Variables para llevar registro del número de imágenes procesadas y máximo permitido\n",
        "image_count = 0\n",
        "max_images = 20\n",
        "\n",
        "# Definir ventanas HU (nivel, ancho)\n",
        "hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "\n",
        "# Para almacenar imágenes procesadas\n",
        "imagen_procesada = []\n",
        "\n",
        "# Crear un diccionario que mapea subj_id a sus imágenes correspondientes\n",
        "print(\"Creando diccionario subj_id a imágenes...\")\n",
        "subj_id_to_images = {}\n",
        "for subj_id, group in df.groupby('subj_id'):\n",
        "    group['total_findings'] = group.drop(['No Finding', 'subj_id', 'id'], axis=1).sum(axis=1)\n",
        "    sorted_group = group.sort_values('total_findings', ascending=False)\n",
        "    subj_id_to_images[subj_id] = sorted_group\n",
        "\n",
        "# Procesar cada grupo de imágenes por paciente\n",
        "print(\"Procesando grupos de imágenes por paciente...\")\n",
        "for subj_id, images_df in subj_id_to_images.items():\n",
        "    if image_count >= max_images:\n",
        "        break\n",
        "\n",
        "    print(f\"Procesando subj_id: {subj_id}\")\n",
        "\n",
        "    # Determinar qué imágenes usar como corte clave, superior e inferior\n",
        "    if len(images_df) == 1:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = key_image\n",
        "        lower_image = key_image\n",
        "    elif len(images_df) == 2:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = upper_image\n",
        "    else:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = images_df.iloc[2]['id']\n",
        "\n",
        "    print(f\"Imágenes seleccionadas: Key: {key_image}, Upper: {upper_image}, Lower: {lower_image}\")\n",
        "\n",
        "    # Leer y combinar las imágenes seleccionadas\n",
        "    combined_image = np.zeros_like(cv2.imread(os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', key_image), cv2.IMREAD_GRAYSCALE), dtype=np.float64)\n",
        "\n",
        "    for weight, img_name in zip([0.7, 0.15, 0.15], [key_image, upper_image, lower_image]):\n",
        "        image_path = os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', img_name)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error al cargar la imagen: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        combined_image += weight * image\n",
        "\n",
        "    # Convertir combined_image a uint8 para futuras operaciones\n",
        "    combined_image = combined_image.astype(np.uint8)\n",
        "\n",
        "    # Aplicar las ventanas HU a la imagen combinada y guardar en la variable\n",
        "    for level, width in hu_windows:\n",
        "        windowed_image = apply_hu_window(combined_image, level, width)\n",
        "        imagen_procesada.append(windowed_image)\n",
        "\n",
        "    # Incrementar el contador de imágenes\n",
        "    image_count += 1\n"
      ],
      "metadata": {
        "id": "Zz6Owyb9Tdml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v6"
      ],
      "metadata": {
        "id": "eCVI1ZxGzfF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Función para aplicar la ventana HU con nivel y ancho\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo archivo CSV...\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv')\n",
        "\n",
        "# Variables para llevar registro del número de subj_ids procesados y máximo permitido\n",
        "subj_id_count = 0\n",
        "max_subj_ids = 30  # Puedes cambiar este valor según tus necesidades\n",
        "\n",
        "# Definir ventanas HU (nivel, ancho)\n",
        "hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "\n",
        "# Para almacenar imágenes y etiquetas procesadas\n",
        "imagen_procesada = []\n",
        "labels_procesadas = []\n",
        "\n",
        "# Crear un diccionario que mapea subj_id a sus imágenes correspondientes\n",
        "print(\"Creando diccionario subj_id a imágenes...\")\n",
        "subj_id_to_images = {}\n",
        "for subj_id, group in df.groupby('subj_id'):\n",
        "    group['total_findings'] = group.drop(['No Finding', 'subj_id', 'id'], axis=1).sum(axis=1)\n",
        "    sorted_group = group.sort_values('total_findings', ascending=False)\n",
        "    subj_id_to_images[subj_id] = sorted_group\n",
        "\n",
        "# Procesar cada grupo de imágenes por paciente\n",
        "print(\"Procesando grupos de imágenes por paciente...\")\n",
        "for subj_id, images_df in subj_id_to_images.items():\n",
        "    if subj_id_count >= max_subj_ids:\n",
        "        break\n",
        "\n",
        "    print(f\"Procesando subj_id: {subj_id}\")\n",
        "\n",
        "    # Determinar qué imágenes usar como corte clave, superior e inferior\n",
        "    if len(images_df) == 1:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = key_image\n",
        "        lower_image = key_image\n",
        "    elif len(images_df) == 2:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = upper_image\n",
        "    else:\n",
        "        key_image = images_df.iloc[0]['id']\n",
        "        upper_image = images_df.iloc[1]['id']\n",
        "        lower_image = images_df.iloc[2]['id']\n",
        "\n",
        "    print(f\"Imágenes seleccionadas: Key: {key_image}, Upper: {upper_image}, Lower: {lower_image}\")\n",
        "\n",
        "    # Leer y combinar las imágenes seleccionadas\n",
        "    combined_image = np.zeros_like(cv2.imread(os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', key_image), cv2.IMREAD_GRAYSCALE), dtype=np.float64)\n",
        "\n",
        "    for weight, img_name in zip([0.7, 0.15, 0.15], [key_image, upper_image, lower_image]):\n",
        "        image_path = os.path.join('/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', img_name)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error al cargar la imagen: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        combined_image += weight * image\n",
        "\n",
        "    # Convertir combined_image a uint8 para futuras operaciones\n",
        "    combined_image = combined_image.astype(np.uint8)\n",
        "\n",
        "    # Aplicar las ventanas HU a la imagen combinada y guardar en la variable\n",
        "    for level, width in hu_windows:\n",
        "        windowed_image = apply_hu_window(combined_image, level, width)\n",
        "        imagen_procesada.append(windowed_image)\n",
        "\n",
        "    # Añadir la etiqueta correspondiente a esta imagen combinada\n",
        "    label = images_df.iloc[0][['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural Thickening', 'Pneumonia', 'Pneumothorax', 'Pneumoperitoneum', 'Pneumomediastinum', 'Subcutaneous Emphysema', 'Tortuous Aorta', 'Calcification of the Aorta', 'No Finding']].values\n",
        "    labels_procesadas.append(label)\n",
        "\n",
        "    # Incrementar el contador de subj_ids\n",
        "    subj_id_count += 1\n"
      ],
      "metadata": {
        "id": "F4czFJX0zgIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt  # Para visualización\n",
        "\n",
        "\n",
        "\n",
        "    # Mostrar imagen combinada sin procesar\n",
        "plt.figure()\n",
        "plt.title(\"Imagen combinada sin procesar\")\n",
        "plt.imshow(combined_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "    # Aplicar las ventanas HU a la imagen combinada y guardar en la variable\n",
        "for level, width in hu_windows:\n",
        "    windowed_image = apply_hu_window(combined_image, level, width)\n",
        "    imagen_procesada.append(windowed_image)\n",
        "        # Mostrar imagen procesada\n",
        "    plt.figure()\n",
        "    plt.title(f\"Imagen procesada con nivel {level} y ancho {width}\")\n",
        "    plt.imshow(windowed_image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n"
      ],
      "metadata": {
        "id": "RoZbwZxK9HXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v7 funcion"
      ],
      "metadata": {
        "id": "uaG4ngKjOyv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "def process_patient_images(csv_path, image_folder_path, max_subj_ids=100):\n",
        "    print(\"Leyendo archivo CSV...\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    subj_id_count = 0\n",
        "    hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "    imagen_procesada = []\n",
        "    labels_procesadas = []\n",
        "\n",
        "    print(\"Creando diccionario subj_id a imágenes...\")\n",
        "    subj_id_to_images = {}\n",
        "    for subj_id, group in df.groupby('subj_id'):\n",
        "        group['total_findings'] = group.drop(['No Finding', 'subj_id', 'id'], axis=1).sum(axis=1)\n",
        "        sorted_group = group.sort_values('total_findings', ascending=False)\n",
        "        subj_id_to_images[subj_id] = sorted_group\n",
        "\n",
        "    print(\"Procesando grupos de imágenes por paciente...\")\n",
        "    for subj_id, images_df in subj_id_to_images.items():\n",
        "        if subj_id_count >= max_subj_ids:\n",
        "            break\n",
        "\n",
        "        print(f\"Procesando subj_id: {subj_id}\")\n",
        "\n",
        "        if len(images_df) == 1:\n",
        "            key_image = images_df.iloc[0]['id']\n",
        "            upper_image = key_image\n",
        "            lower_image = key_image\n",
        "        elif len(images_df) == 2:\n",
        "            key_image = images_df.iloc[0]['id']\n",
        "            upper_image = images_df.iloc[1]['id']\n",
        "            lower_image = upper_image\n",
        "        else:\n",
        "            key_image = images_df.iloc[0]['id']\n",
        "            upper_image = images_df.iloc[1]['id']\n",
        "            lower_image = images_df.iloc[2]['id']\n",
        "\n",
        "        print(f\"Imágenes seleccionadas: Key: {key_image}, Upper: {upper_image}, Lower: {lower_image}\")\n",
        "\n",
        "        combined_image = np.zeros_like(cv2.imread(os.path.join(image_folder_path, key_image), cv2.IMREAD_GRAYSCALE), dtype=np.float64)\n",
        "\n",
        "        for weight, img_name in zip([0.7, 0.15, 0.15], [key_image, upper_image, lower_image]):\n",
        "            image_path = os.path.join(image_folder_path, img_name)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if image is None:\n",
        "                print(f\"Error al cargar la imagen: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            combined_image += weight * image\n",
        "\n",
        "        combined_image = combined_image.astype(np.uint8)\n",
        "\n",
        "        for level, width in hu_windows:\n",
        "            windowed_image = apply_hu_window(combined_image, level, width)\n",
        "            imagen_procesada.append(windowed_image)\n",
        "\n",
        "        label = images_df.iloc[0][['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural Thickening', 'Pneumonia', 'Pneumothorax', 'Pneumoperitoneum', 'Pneumomediastinum', 'Subcutaneous Emphysema', 'Tortuous Aorta', 'Calcification of the Aorta', 'No Finding']].values\n",
        "        labels_procesadas.append(label)\n",
        "\n",
        "        subj_id_count += 1\n",
        "\n",
        "    return imagen_procesada, labels_procesadas\n",
        "\n"
      ],
      "metadata": {
        "id": "zgaSXlmaO0ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v8 binario clasificatorio"
      ],
      "metadata": {
        "id": "O5EwLrbnt8TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Función para aplicar la ventana HU\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo el archivo CSV...\")\n",
        "csv_path = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filtrar filas con exactamente una enfermedad o ninguna\n",
        "print(\"Filtrando filas...\")\n",
        "df['sum_conditions'] = df.drop(['id', 'subj_id'], axis=1).sum(axis=1)\n",
        "df_single_condition = df[df['sum_conditions'] <= 1]\n",
        "\n",
        "# Balancear el conjunto de datos\n",
        "print(\"Balanceando el conjunto de datos...\")\n",
        "no_finding_df = df_single_condition[df_single_condition['No Finding'] == 1]\n",
        "disease_df = df_single_condition[df_single_condition['No Finding'] == 0]\n",
        "min_size = min(len(no_finding_df), len(disease_df))\n",
        "balanced_df = pd.concat([no_finding_df.sample(min_size), disease_df.sample(min_size)])\n",
        "\n",
        "# Inicialización\n",
        "print(\"Inicializando...\")\n",
        "max_subj_ids = 300\n",
        "subj_id_count = 0\n",
        "hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "imagen_procesada = []\n",
        "labels_procesadas = []\n",
        "seen_subj_ids = set()\n",
        "\n",
        "# Carpetas de imágenes\n",
        "base_folder = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train'\n",
        "image_folders = [os.path.join(base_folder, f'batch_{i}') for i in range(1, 28)]\n",
        "\n",
        "\n",
        "# Procesamiento\n",
        "print(\"Comenzando el procesamiento...\")\n",
        "for subj_id, images_df in balanced_df.groupby('subj_id'):\n",
        "    stop_processing = False  # Reinicia la variable de control para cada nuevo subj_id\n",
        "    if subj_id in seen_subj_ids or subj_id_count >= max_subj_ids:\n",
        "        continue\n",
        "    seen_subj_ids.add(subj_id)\n",
        "    subj_id_count += 1\n",
        "    print(f\"Procesando subj_id {subj_id}...\")\n",
        "\n",
        "    for img_name in images_df['id']:\n",
        "        if stop_processing:\n",
        "            break\n",
        "        for folder in image_folders:\n",
        "            image_path = os.path.join(folder, img_name)\n",
        "            if os.path.exists(image_path):\n",
        "                print(f\"Leyendo la imagen {img_name} desde {image_path}...\")\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                print(f\"Aplicando ventanas HU para la imagen {img_name}...\")\n",
        "                for level, width in hu_windows:\n",
        "                    windowed_image = apply_hu_window(image, level, width)\n",
        "                    imagen_procesada.append(windowed_image)\n",
        "\n",
        "                label = images_df.loc[images_df['id'] == img_name, 'No Finding'].values[0]\n",
        "                labels_procesadas.append(label)\n",
        "                print(f\"Etiqueta añadida: {label}\")\n",
        "\n",
        "                # Detener el procesamiento para este subj_id\n",
        "                stop_processing = True\n",
        "                break\n",
        "\n",
        "print(\"Procesamiento completado.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "McEvUuAUuAaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(labels_procesadas)\n",
        "label_counts\n"
      ],
      "metadata": {
        "id": "cCxRVATLLL4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Mostrar las primeras 20 imágenes\n",
        "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(20):\n",
        "    axes[i].imshow(imagen_procesada[i], cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f'Imagen {i+1}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hZC0it-HwXG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v9 binario mas de 1 posibilidad"
      ],
      "metadata": {
        "id": "t-aQUQzkwWGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Función para aplicar la ventana HU con nivel y ancho\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo archivo CSV...\")\n",
        "csv_path = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filtrar filas con exactamente una enfermedad\n",
        "columns_to_drop = ['id', 'subj_id']\n",
        "df_filtered = df.drop(columns=columns_to_drop)\n",
        "df_filtered['sum_conditions'] = df_filtered.sum(axis=1)\n",
        "df_single_condition = df[df_filtered['sum_conditions'] == 1]\n",
        "df_single_condition.loc[:, 'subj_id'] = df['subj_id']\n",
        "\n",
        "# Variables para llevar registro del número de subj_ids procesados y máximo permitido\n",
        "subj_id_count = 0\n",
        "max_subj_ids = 100\n",
        "\n",
        "# Definir ventanas HU (nivel, ancho)\n",
        "hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "\n",
        "# Para almacenar imágenes y etiquetas procesadas\n",
        "imagen_procesada = []\n",
        "labels_procesadas = []\n",
        "\n",
        "# Carpetas donde se pueden encontrar las imágenes\n",
        "image_folders = ['/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_1', '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_2', '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_3', '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_4', '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_5', '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Train/batch_6']\n",
        "\n",
        "# Procesar cada grupo de imágenes por paciente\n",
        "print(\"Procesando grupos de imágenes por paciente...\")\n",
        "for subj_id, images_df in df_single_condition.groupby('subj_id'):\n",
        "    if subj_id_count >= max_subj_ids:\n",
        "        break\n",
        "\n",
        "    print(f\"Procesando subj_id: {subj_id}\")\n",
        "\n",
        "    for img_name in images_df['id']:\n",
        "        for folder in image_folders:\n",
        "            image_path = os.path.join(folder, img_name)\n",
        "            if os.path.exists(image_path):\n",
        "                # Cargar y procesar la imagen\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if image is None:\n",
        "                    print(f\"Error al cargar la imagen: {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Aplicar las ventanas HU a la imagen y guardar en imagen_procesada\n",
        "                for level, width in hu_windows:\n",
        "                    windowed_image = apply_hu_window(image, level, width)\n",
        "                    imagen_procesada.append(windowed_image)\n",
        "\n",
        "                # Añadir la etiqueta correspondiente a esta imagen\n",
        "                label = images_df.iloc[0].drop(['No Finding', 'id', 'subj_id']).values\n",
        "                labels_procesadas.append(label)\n",
        "\n",
        "                break\n",
        "\n",
        "    # Incrementar el contador de subj_ids\n",
        "    subj_id_count += 1\n"
      ],
      "metadata": {
        "id": "mVbXonRdwX4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen_procesada"
      ],
      "metadata": {
        "id": "1zJ-0RiGkRZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_procesadas"
      ],
      "metadata": {
        "id": "gOQ1ysGflR_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Mostrar las primeras 20 imágenes\n",
        "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(20):\n",
        "    axes[i].imshow(imagen_procesada[i], cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f'Imagen {i+1}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gRsuNeCgk99D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v10 binario multitask"
      ],
      "metadata": {
        "id": "TTP6SeYQ_Uik"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5roG8ql_XKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJi2G6__g-yQ"
      },
      "source": [
        "#ResNext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-arquitectura"
      ],
      "metadata": {
        "id": "R0ttbIV-f3pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# Convertir la lista a un array de NumPy\n",
        "imagen_procesada_np = np.array(imagen_procesada)\n",
        "\n",
        "# Realizar la normalización\n",
        "imagen_procesada_np = imagen_procesada_np / 255.0\n",
        "\n",
        "\n",
        "\n",
        "tensor = torch.from_numpy(imagen_procesada_np)\n",
        "labels_tensor = torch.tensor(labels_procesadas, dtype=torch.float32)\n",
        "\n"
      ],
      "metadata": {
        "id": "IQVA0tq3CEaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#arquitectura"
      ],
      "metadata": {
        "id": "f5BJgUVBqIf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "# Self-Attention module\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels, heads):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.q = nn.Linear(in_channels, in_channels // heads)\n",
        "        self.k = nn.Linear(in_channels, in_channels // heads)\n",
        "        self.v = nn.Linear(in_channels, in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.q(x)\n",
        "        k = self.k(x)\n",
        "        v = self.v(x)\n",
        "\n",
        "        attn = torch.matmul(q, k.transpose(2, 1))\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        output = torch.matmul(attn, v)\n",
        "        return output\n",
        "\n",
        "# Feature Pyramid Network module\n",
        "class FPN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FPN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2048, 256, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# Custom Head for task-specific layers\n",
        "class CustomHead(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(CustomHead, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, 512)  # Adjusted to match the dimension of attn_features_flattened\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, out_features)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Main Feature Extractor class\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        # Initialize ResNeXt-101\n",
        "        self.resnext = models.resnext101_32x8d(pretrained=True)\n",
        "\n",
        "        # Remove the fully connected layer to get only the features\n",
        "        self.features = nn.Sequential(*list(self.resnext.children())[:-2])\n",
        "\n",
        "        # Initialize FPN\n",
        "        self.fpn = FPN()\n",
        "\n",
        "        # Initialize Self-Attention module\n",
        "        self.self_attention = SelfAttention(in_channels=256, heads=2)\n",
        "\n",
        "        # Initialize Custom Head\n",
        "        self.custom_head = CustomHead(262144, num_classes)  # Adjusted the in_features to match attn_features_flattened\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features using ResNeXt\n",
        "        resnext_features = self.features(x)\n",
        "\n",
        "        # Merge features using FPN\n",
        "        fpn_features = self.fpn(resnext_features)\n",
        "\n",
        "        # Flatten features to be compatible with self-attention\n",
        "        fpn_features_flattened = fpn_features.view(fpn_features.size(0), fpn_features.size(1), -1).permute(0, 2, 1)\n",
        "\n",
        "        # Apply self-attention for feature fusion\n",
        "        attn_features = self.self_attention(fpn_features_flattened)\n",
        "\n",
        "        # Reshape the features back to their original shape\n",
        "        attn_features = attn_features.permute(0, 2, 1).view(fpn_features.size())\n",
        "\n",
        "        # Make the tensor contiguous and flatten the features for the custom head\n",
        "        attn_features_flattened = attn_features.contiguous().view(attn_features.size(0), -1)\n",
        "\n",
        "        # Apply custom head\n",
        "        out = self.custom_head(attn_features_flattened)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Create an instance of the model with the specific number of classes for your problem\n",
        "YOUR_NUM_CLASSES = 1  # Replace with the actual number of classes you have\n",
        "model = FeatureExtractor(num_classes=YOUR_NUM_CLASSES)\n"
      ],
      "metadata": {
        "id": "iLY0ZOLrCWBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b3993b-7e1f-46a8-c3bf-b51cd6de7b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_32X8D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n",
            "100%|██████████| 340M/340M [00:01<00:00, 211MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#v1"
      ],
      "metadata": {
        "id": "v9sL3PCVf5TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor.float()  # Convierte a float si es necesario\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to('cuda')\n",
        "    model.to('cuda')\n"
      ],
      "metadata": {
        "id": "fFByFNzfJ2KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir el tensor de tipo Byte a Float\n",
        "tensor = tensor.to(torch.float32)\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for better performance\n",
        "    for i in range(tensor.shape[0]):\n",
        "        # Take an individual image from the original tensor\n",
        "        single_image = tensor[i, :, :]\n",
        "\n",
        "        # Add a dimension for the channel and replicate to get 3 channels\n",
        "        single_image = single_image.unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1)"
      ],
      "metadata": {
        "id": "FvsCtr5JsMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiplicar etiquetas"
      ],
      "metadata": {
        "id": "W9Z8hLj63XIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir cada array de dtype=object a dtype=float32\n",
        "labels_procesadas = [np.array(x, dtype=np.float32) for x in labels_procesadas]\n",
        "\n",
        "# Convertir la lista de arrays a una sola matriz NumPy\n",
        "labels_np = np.array(labels_procesadas, dtype=np.float32)\n",
        "\n",
        "# Verificar que se haya convertido correctamente\n",
        "if labels_np.dtype == object:\n",
        "    raise ValueError(\"labels_procesadas contiene elementos no numéricos o de tipos mixtos\")\n",
        "\n",
        "# Repetir cada fila 5 veces para que coincida con el número de imágenes\n",
        "labels_repeated = np.repeat(labels_np, 5, axis=0)\n",
        "\n",
        "# Convertirlo de nuevo a un tensor de PyTorch\n",
        "labels_tensor = torch.tensor(labels_repeated, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "UUoj4OzY3Ynm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de bibliotecas necesarias\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "# Crear CustomDataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "# Tus imágenes procesadas (convertidas a tensor) y etiquetas (aquí pongo un ejemplo de etiquetas)\n",
        "# Suponiendo que imagen_procesada_tensor tiene forma [N, H, W] donde N es el número de imágenes, H la altura y W la anchura\n",
        "imagen_procesada_tensor_3ch = tensor.unsqueeze(1).repeat(1, 3, 1, 1)  # Ahora la forma es [N, 3, H, W]\n",
        "\n",
        "\n",
        "\n",
        "# Parámetros\n",
        "num_classes = 20  # Reemplaza con el número real de clases que tienes\n",
        "learning_rate = 0.003\n",
        "batch_size = 1\n",
        "n_epochs = 10\n",
        "\n",
        "# Crear una instancia del modelo\n",
        "model = FeatureExtractor(num_classes=num_classes)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Adaptar DataLoader\n",
        "# Conjunto de datos y cargador de datos\n",
        "train_data = TensorDataset(imagen_procesada_tensor_3ch, labels_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Mover el modelo a la GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      # Mover los datos y las etiquetas a la GPU\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        # Poner a cero los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calcular la pérdida\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualización de pesos\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Entrenamiento completado.\")\n"
      ],
      "metadata": {
        "id": "woBab_2rf7Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#entrenamiento verdadero v2"
      ],
      "metadata": {
        "id": "wYOQnKkX9MCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "# Convertir el tensor de tipo Byte a Float\n",
        "tensor = tensor.to(torch.float32)\n",
        "\n",
        "# Lista para almacenar imágenes con 3 canales\n",
        "tensor_3ch_list = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for better performance\n",
        "    for i in range(tensor.shape[0]):\n",
        "        # Take an individual image from the original tensor\n",
        "        single_image = tensor[i, :, :]\n",
        "\n",
        "        # Add a dimension for the channel and replicate to get 3 channels\n",
        "        single_image_3ch = single_image.unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Agregar a la lista\n",
        "        tensor_3ch_list.append(single_image_3ch)\n",
        "\n",
        "# Concatenar todas las imágenes en un solo tensor\n",
        "imagen_procesada_tensor_3ch = torch.cat(tensor_3ch_list, dim=0)\n",
        "\n",
        "\n",
        "# Tus etiquetas procesadas y convertidas a NumPy\n",
        "labels_np = np.array([np.array(x, dtype=np.float32) for x in labels_procesadas], dtype=np.float32)\n",
        "\n",
        "# Repetir cada fila 5 veces para que coincida con el número de imágenes\n",
        "labels_repeated = np.repeat(labels_np, 5, axis=0)\n",
        "\n",
        "# Convertirlo de nuevo a un tensor de PyTorch\n",
        "labels_tensor = torch.tensor(labels_repeated, dtype=torch.float32)\n",
        "\n",
        "# Dividir en entrenamiento y validación\n",
        "# Dividir en entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(imagen_procesada_tensor_3ch.cpu().numpy(), labels_tensor.cpu().numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Convertir de nuevo a tensores\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "# Crear CustomDataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "# Parámetros\n",
        "num_classes = 20\n",
        "learning_rate = 0.003\n",
        "batch_size = 1\n",
        "n_epochs = 10\n",
        "\n",
        "# Crear una instancia del modelo (asegúrate de que FeatureExtractor esté definido)\n",
        "model = FeatureExtractor(num_classes=num_classes)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Adaptar DataLoader\n",
        "train_data = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data = CustomDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Mover el modelo a la GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to('cuda'), target.to('cuda')\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            pred = (torch.sigmoid(output) > 0.5).float()\n",
        "            correct += (pred == target).float().sum()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / (len(val_loader.dataset) * num_classes)\n",
        "    print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)*num_classes} ({accuracy:.0f}%)')\n",
        "\n",
        "print(\"Entrenamiento completado.\")\n"
      ],
      "metadata": {
        "id": "W34VmR_m9Occ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#entrenamiento con mas info V3"
      ],
      "metadata": {
        "id": "bzu4otcLBQ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "# Convertir el tensor de tipo Byte a Float\n",
        "tensor = tensor.to(torch.float32)\n",
        "\n",
        "# Lista para almacenar imágenes con 3 canales\n",
        "tensor_3ch_list = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for better performance\n",
        "    for i in range(tensor.shape[0]):\n",
        "        single_image = tensor[i, :, :]\n",
        "        single_image_3ch = single_image.unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1)\n",
        "        tensor_3ch_list.append(single_image_3ch)\n",
        "\n",
        "imagen_procesada_tensor_3ch = torch.cat(tensor_3ch_list, dim=0)\n",
        "\n",
        "labels_np = np.array([np.array(x, dtype=np.float32) for x in labels_procesadas], dtype=np.float32)\n",
        "labels_repeated = np.repeat(labels_np, 5, axis=0)\n",
        "labels_tensor = torch.tensor(labels_repeated, dtype=torch.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(imagen_procesada_tensor_3ch.cpu().numpy(), labels_tensor.cpu().numpy(), test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "num_classes = 20\n",
        "learning_rate = 0.001\n",
        "batch_size = 1\n",
        "n_epochs = 3\n",
        "\n",
        "# Asegúrate de que FeatureExtractor esté definido\n",
        "model = FeatureExtractor(num_classes=num_classes)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_data = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data = CustomDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to('cuda'), target.to('cuda')\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            pred = torch.sigmoid(output)\n",
        "            y_true.extend(target.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "            pred = (pred > 0.6).float()\n",
        "            correct += (pred == target).float().sum()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / (len(val_loader.dataset) * num_classes)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred > 0.6, average='samples', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred > 0.6, average='samples')\n",
        "    f1 = f1_score(y_true, y_pred > 0.6, average='samples')\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)*num_classes} ({accuracy:.0f}%)')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "Ya1X_Tn7BS-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V4 binaria Fase 1"
      ],
      "metadata": {
        "id": "rzWCJo8Z2Db7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "# Convertir el tensor de tipo Byte a Float\n",
        "tensor = tensor.to(torch.float32)\n",
        "\n",
        "# Lista para almacenar imágenes con 3 canales\n",
        "tensor_3ch_list = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for better performance\n",
        "    for i in range(tensor.shape[0]):\n",
        "        single_image = tensor[i, :, :]\n",
        "        single_image_3ch = single_image.unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1)\n",
        "        tensor_3ch_list.append(single_image_3ch)\n",
        "\n",
        "imagen_procesada_tensor_3ch = torch.cat(tensor_3ch_list, dim=0)\n",
        "\n",
        "labels_np = np.array([np.array(x, dtype=np.float32) for x in labels_procesadas], dtype=np.float32)\n",
        "labels_repeated = np.repeat(labels_np, 5, axis=0)\n",
        "labels_tensor = torch.tensor(labels_repeated, dtype=torch.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(imagen_procesada_tensor_3ch.cpu().numpy(), labels_tensor.cpu().numpy(), test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "num_classes = 1\n",
        "learning_rate = 0.003\n",
        "batch_size = 4\n",
        "n_epochs = 5\n",
        "\n",
        "# Asegúrate de que FeatureExtractor esté definido\n",
        "model = FeatureExtractor(num_classes=num_classes)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_data = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data = CustomDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "roc_auc_list = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        target = target.unsqueeze(-1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to('cuda'), target.to('cuda')\n",
        "            target = target.unsqueeze(-1)\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            pred = torch.sigmoid(output)\n",
        "            y_true.extend(target.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "            pred = (pred > 0.6).float()\n",
        "            correct += (pred == target).float().sum()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / (len(val_loader.dataset) * num_classes)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred > 0.6, zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred > 0.6)\n",
        "    f1 = f1_score(y_true, y_pred > 0.6)\n",
        "\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)*num_classes} ({accuracy:.0f}%)')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "Oiqsw0pk2Gfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V2 Binaria Fase 1 optimizacion"
      ],
      "metadata": {
        "id": "38NFkkElaGaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Suponiendo que 'tensor' y 'labels_procesadas' ya están definidos\n",
        "tensor = tensor.to(torch.float32)\n",
        "\n",
        "imagen_procesada_tensor_3ch = torch.zeros((tensor.shape[0], 3, tensor.shape[1], tensor.shape[2]), dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(tensor.shape[0]):\n",
        "        imagen_procesada_tensor_3ch[i] = tensor[i].unsqueeze(0).expand(3, -1, -1)\n",
        "\n",
        "labels_repeated = np.repeat(np.array(labels_procesadas, dtype=np.float32), 5, axis=0)\n",
        "labels_tensor = torch.tensor(labels_repeated, dtype=torch.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(imagen_procesada_tensor_3ch.cpu().numpy(), labels_tensor.cpu().numpy(), test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "num_classes = 1\n",
        "learning_rate = 0.001\n",
        "batch_size = 6\n",
        "n_epochs = 5\n",
        "\n",
        "# Asegúrate de que FeatureExtractor esté definido\n",
        "# model = FeatureExtractor(num_classes=num_classes)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_data = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data = CustomDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Entrenamiento con métricas\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        target = target.unsqueeze(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            labels_cpu = target.cpu().numpy()\n",
        "            predictions_cpu = torch.sigmoid(output).cpu().numpy()\n",
        "            all_labels.extend(labels_cpu)\n",
        "            all_predictions.extend(predictions_cpu)\n",
        "\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            avg_loss = running_loss / 10\n",
        "            precision = precision_score(np.array(all_labels), np.array(all_predictions) > 0.5, zero_division=1)\n",
        "            recall = recall_score(np.array(all_labels), np.array(all_predictions) > 0.5)\n",
        "            f1 = f1_score(np.array(all_labels), np.array(all_predictions) > 0.5)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{n_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                  f\"Loss: {avg_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "            running_loss = 0.0\n",
        "            all_labels = []\n",
        "            all_predictions = []\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to('cuda'), target.to('cuda')\n",
        "            target = target.unsqueeze(-1)\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            pred = torch.sigmoid(output)\n",
        "            y_true.extend(target.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "            pred = (pred > 0.6).float()\n",
        "            correct += (pred == target).float().sum()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / (len(val_loader.dataset) * num_classes)\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred > 0.5, zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred > 0.5)\n",
        "    f1 = f1_score(y_true, y_pred > 0.5)\n",
        "\n",
        "    print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)*num_classes} ({accuracy:.0f}%)')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "WTEzUd8fZa7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation set: Average loss: 0.3447, Accuracy: 102.0/240 (43%)\n",
        "Precision: 0.5750, Recall: 1.0000, F1 Score: 0.7302"
      ],
      "metadata": {
        "id": "1qlozuGd1p3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation set: Average loss: 0.1346, Accuracy: 202.0/330 (61%)\n",
        "Precision: 0.6121, Recall: 1.0000, F1 Score: 0.7594"
      ],
      "metadata": {
        "id": "VzMGSOTw348V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation set: Average loss: 0.1350, Accuracy: 176.0/450 (39%)\n",
        "Precision: 0.6089, Recall: 1.0000, F1 Score: 0.7569"
      ],
      "metadata": {
        "id": "eZUEPnOM66C-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation set: Average loss: 0.1112, Accuracy: 276.0/450 (61%)\n",
        "Precision: 0.6133, Recall: 1.0000, F1 Score: 0.7603\n"
      ],
      "metadata": {
        "id": "X7Z9kM279ytD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##guardar modelo"
      ],
      "metadata": {
        "id": "NN9CB_QMQaXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/3. Recursos/Modelos entrenados/CT-model/modelo_entrenado_A100.pth')\n"
      ],
      "metadata": {
        "id": "FR3YtcMTQZ7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##cargar el modelo"
      ],
      "metadata": {
        "id": "jyTuplhxhsIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FeatureExtractor(num_classes=1)  # Inicializar el modelo\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/3. Recursos/Modelos entrenados/CT-model/modelo_entrenado_A100.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GC9j6FQhvXR",
        "outputId": "afc3c49a-6695-4bac-a782-d31cfd66608d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ejecucion de test"
      ],
      "metadata": {
        "id": "w4zTHB7ZPlgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##preprocesamiento"
      ],
      "metadata": {
        "id": "TE9DmgHZPnPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de cómo usar la función\n",
        "csv_path = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_test.csv'\n",
        "image_folder_path = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Test/batch_1'\n",
        "max_subj_ids = 3\n",
        "\n",
        "imagen_procesada, labels_procesadas = process_patient_images(csv_path, image_folder_path, max_subj_ids)"
      ],
      "metadata": {
        "id": "uh21EH77PpJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen_procesada"
      ],
      "metadata": {
        "id": "xhZ0BLfv5Ftk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##predicción"
      ],
      "metadata": {
        "id": "wKRo_wsdPptZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### procesar tensor"
      ],
      "metadata": {
        "id": "7Gj6ide3lwEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar PyTorch\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Crear una instancia del modelo (asegúrate de que sea exactamente el mismo modelo que usaste durante el entrenamiento)\n",
        "model = FeatureExtractor(num_classes=1)  # Ajusta 'num_classes' según tu caso\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Cargar el state_dict en el modelo\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/3. Recursos/Modelos entrenados/CT-model/modelo_entrenado_A100.pth'))\n",
        "\n",
        "# Asegúrate de que el modelo esté en modo de evaluación\n",
        "model.eval()\n",
        "\n",
        "# Convertir la lista a un array de NumPy\n",
        "imagen_procesada_np = np.array(imagen_procesada)\n",
        "\n",
        "# Realizar la normalización\n",
        "imagen_procesada_np = imagen_procesada_np / 255.0\n",
        "\n",
        "# Convertir el array de NumPy normalizado a tensor de PyTorch\n",
        "tensor = torch.tensor(imagen_procesada_np, dtype=torch.float32).to('cuda')\n",
        "\n",
        "# Procesar el tensor para tener 3 canales\n",
        "tensor_3ch_list = []\n",
        "with torch.no_grad():  # Desactivar el cálculo del gradiente\n",
        "    for i in range(tensor.shape[0]):\n",
        "        single_image = tensor[i, :, :]\n",
        "        single_image_3ch = single_image.unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1)\n",
        "        tensor_3ch_list.append(single_image_3ch)\n",
        "\n",
        "imagen_procesada_tensor_3ch = torch.cat(tensor_3ch_list, dim=0)\n",
        "\n",
        "# Realizar la predicción\n",
        "with torch.no_grad():\n",
        "    output = model(imagen_procesada_tensor_3ch)\n",
        "\n",
        "# Post-procesamiento (por ejemplo, aplicar la función sigmoide para obtener probabilidades)\n",
        "predicted_probabilities = torch.sigmoid(output).cpu().numpy()\n",
        "\n",
        "# Aplicar un umbral para obtener clases\n",
        "predicted_classes = (predicted_probabilities > 0.2).astype(int)\n",
        "\n",
        "# Ahora, 'predicted_classes' contiene las clases predichas y 'predicted_probabilities' contiene las probabilidades\n"
      ],
      "metadata": {
        "id": "M5nnwW7xlyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modificación del código para realizar predicciones una imagen a la vez\n",
        "\n",
        "# Lista para almacenar las predicciones de clases y probabilidades\n",
        "predicted_classes_list = []\n",
        "predicted_probabilities_list = []\n",
        "\n",
        "# Número de imágenes a predecir\n",
        "num_images = imagen_procesada_tensor_3ch.shape[0]\n",
        "\n",
        "# Realizar la predicción una imagen a la vez\n",
        "for i in range(num_images):\n",
        "    # Tomar una sola imagen y añadir una dimensión de lote\n",
        "    single_image_tensor = imagen_procesada_tensor_3ch[i].unsqueeze(0).to('cuda')\n",
        "\n",
        "    # Realizar la predicción\n",
        "    with torch.no_grad():\n",
        "        output = model(single_image_tensor)\n",
        "\n",
        "        # Post-procesamiento para obtener probabilidades\n",
        "        predicted_probabilities = torch.sigmoid(output).cpu().numpy()\n",
        "\n",
        "        # Aplicar un umbral para obtener clases\n",
        "        predicted_classes = (predicted_probabilities > 0.2).astype(int)\n",
        "\n",
        "        # Almacenar las predicciones\n",
        "        predicted_classes_list.append(predicted_classes)\n",
        "        predicted_probabilities_list.append(predicted_probabilities)\n",
        "\n",
        "# Convertir la lista de predicciones de clases y probabilidades en arrays de NumPy\n",
        "predicted_classes_array = np.array(predicted_classes_list).squeeze()\n",
        "predicted_probabilities_array = np.array(predicted_probabilities_list).squeeze()\n",
        "\n",
        "predicted_classes_array, predicted_probabilities_array\n"
      ],
      "metadata": {
        "id": "a4_qQMZ1580C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0kbRLxG6KuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime o guarda las probabilidades y clases predichas\n",
        "print(\"Probabilidades predichas:\", predicted_probabilities)\n",
        "print(\"Clases predichas:\", predicted_classes)"
      ],
      "metadata": {
        "id": "ZLHXPJWhqbVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###prediccion"
      ],
      "metadata": {
        "id": "k9lhli2mly8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumiendo que ya has cargado tu modelo como 'model'\n",
        "model.eval()  # Poner el modelo en modo de evaluación\n",
        "\n",
        "# Asumiendo que 'test_data' es tu tensor de datos de entrada\n",
        "# Si tus datos están en una lista o array de NumPy, conviértelos a un tensor de PyTorch primero\n",
        "test_data_tensor = torch.tensor(test_data, dtype=torch.float32).to('cuda')  # Reemplaza 'test_data' con tus datos de entrada\n",
        "\n",
        "# Realizar la predicción\n",
        "with torch.no_grad():  # Desactivar el cálculo del gradiente para mejorar el rendimiento\n",
        "    output = model(test_data_tensor)\n",
        "\n",
        "# Aplicar la función sigmoide para obtener probabilidades\n",
        "predicted_probabilities = torch.sigmoid(output).cpu().numpy()\n",
        "\n",
        "# Si necesitas clases en lugar de probabilidades, puedes aplicar un umbral\n",
        "predicted_classes = (predicted_probabilities > 0.6).astype(int)\n"
      ],
      "metadata": {
        "id": "173--uthPrZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#carpeta test"
      ],
      "metadata": {
        "id": "riViAk0ZNkFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Función para aplicar la ventana HU\n",
        "def apply_hu_window(image_np, level, width):\n",
        "    min_value = level - (width / 2)\n",
        "    max_value = level + (width / 2)\n",
        "    windowed_image = np.clip(image_np, min_value, max_value)\n",
        "    windowed_image = (windowed_image - min_value) / (max_value - min_value) * 255\n",
        "    return windowed_image.astype(np.uint8)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "print(\"Leyendo el archivo CSV...\")\n",
        "csv_path = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/PruneCXR/miccai2023_nih-cxr-lt_labels_test.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filtrar filas con exactamente una enfermedad o ninguna\n",
        "print(\"Filtrando filas...\")\n",
        "df['sum_conditions'] = df.drop(['id', 'subj_id'], axis=1).sum(axis=1)\n",
        "df_single_condition = df[df['sum_conditions'] <= 1]\n",
        "\n",
        "# Balancear el conjunto de datos\n",
        "print(\"Balanceando el conjunto de datos...\")\n",
        "no_finding_df = df_single_condition[df_single_condition['No Finding'] == 1]\n",
        "disease_df = df_single_condition[df_single_condition['No Finding'] == 0]\n",
        "min_size = min(len(no_finding_df), len(disease_df))\n",
        "balanced_df = pd.concat([no_finding_df.sample(min_size), disease_df.sample(min_size)])\n",
        "\n",
        "# Inicialización\n",
        "print(\"Inicializando...\")\n",
        "max_subj_ids = 2\n",
        "subj_id_count = 0\n",
        "hu_windows = [(400, 2000), (240, 350), (50, 350), (200, 350), (30, 250)]\n",
        "imagen_procesada = []\n",
        "labels_procesadas = []\n",
        "seen_subj_ids = set()\n",
        "\n",
        "# Carpetas de imágenes\n",
        "base_folder = '/content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Test'\n",
        "image_folders = [os.path.join(base_folder, f'batch_{i}') for i in range(1, 28)]\n",
        "\n",
        "\n",
        "# Procesamiento\n",
        "print(\"Comenzando el procesamiento...\")\n",
        "for subj_id, images_df in balanced_df.groupby('subj_id'):\n",
        "    stop_processing = False  # Reinicia la variable de control para cada nuevo subj_id\n",
        "    if subj_id in seen_subj_ids or subj_id_count >= max_subj_ids:\n",
        "        continue\n",
        "    seen_subj_ids.add(subj_id)\n",
        "    subj_id_count += 1\n",
        "    print(f\"Procesando subj_id {subj_id}...\")\n",
        "\n",
        "    for img_name in images_df['id']:\n",
        "        if stop_processing:\n",
        "            break\n",
        "        for folder in image_folders:\n",
        "            image_path = os.path.join(folder, img_name)\n",
        "            if os.path.exists(image_path):\n",
        "                print(f\"Leyendo la imagen {img_name} desde {image_path}...\")\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if image is None:\n",
        "                    continue\n",
        "\n",
        "                print(f\"Aplicando ventanas HU para la imagen {img_name}...\")\n",
        "                for level, width in hu_windows:\n",
        "                    windowed_image = apply_hu_window(image, level, width)\n",
        "                    imagen_procesada.append(windowed_image)\n",
        "\n",
        "                label = images_df.loc[images_df['id'] == img_name, 'No Finding'].values[0]\n",
        "                labels_procesadas.append(label)\n",
        "                print(f\"Etiqueta añadida: {label}\")\n",
        "\n",
        "                # Detener el procesamiento para este subj_id\n",
        "                stop_processing = True\n",
        "                break\n",
        "\n",
        "print(\"Procesamiento completado.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-0-EkYSNpbk",
        "outputId": "ba4db424-c769-449e-b082-48cc99737b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo el archivo CSV...\n",
            "Filtrando filas...\n",
            "Balanceando el conjunto de datos...\n",
            "Inicializando...\n",
            "Comenzando el procesamiento...\n",
            "Procesando subj_id 13...\n",
            "Leyendo la imagen 00000013_000.png desde /content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Test/batch_1/00000013_000.png...\n",
            "Aplicando ventanas HU para la imagen 00000013_000.png...\n",
            "Etiqueta añadida: 1\n",
            "Procesando subj_id 32...\n",
            "Leyendo la imagen 00000032_019.png desde /content/drive/MyDrive/1. proyectos/trabajo fiver/proyectos/Implementacion_radiografia_18_9_23/imagenes/Test/batch_1/00000032_019.png...\n",
            "Aplicando ventanas HU para la imagen 00000032_019.png...\n",
            "Etiqueta añadida: 1\n",
            "Procesamiento completado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#localización"
      ],
      "metadata": {
        "id": "BFWzygng-VQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificación de Localización:\n",
        "\n",
        "Cortar el segmento de la imagen que el modelo ha señalado como el área donde está la enfermedad.\n",
        "Utilizar el modelo de clasificación inicial para evaluar este segmento recortado.\n",
        "Si el modelo ya no detecta la enfermedad, se considera que la localización fue exitosa.\n",
        "Si el modelo sigue detectando la enfermedad, se considera que la localización fue incorrecta."
      ],
      "metadata": {
        "id": "Gb5y0AU2-XEI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "giJo3pCUdFi9",
        "pP88UH-JzmZ9",
        "bYA-L8Ssznys",
        "z7aI7JHRzrTF",
        "rg8sIXbbcGw7",
        "qihfQiroTedM",
        "eCVI1ZxGzfF4",
        "uaG4ngKjOyv6",
        "t-aQUQzkwWGw",
        "R0ttbIV-f3pI",
        "v9sL3PCVf5TI",
        "wYOQnKkX9MCC",
        "bzu4otcLBQ9b"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1JTMUomC9S0-zVhhz09Z0Yxhrao-lE24x",
      "authorship_tag": "ABX9TyNE6VfTQV5sJ745iTsvU/L3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}